{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b03938c",
   "metadata": {},
   "source": [
    "# Post-Processing Predicted Camera Pose and CO3D Ground Truth Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0b9ed",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d49dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_images_txt(file_path):\n",
    "    \"\"\"\n",
    "    解析 images.txt 檔案，提取相機姿態資訊。\n",
    "    \"\"\"\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 跳過前四行的註解和統計資訊\n",
    "    i = 4\n",
    "    while i < len(lines):\n",
    "        # 這是包含姿態資訊的行\n",
    "        pose_line = lines[i].strip().split()\n",
    "        image_id = int(pose_line[0])\n",
    "        qw, qx, qy, qz = map(float, pose_line[1:5])\n",
    "        tx, ty, tz = map(float, pose_line[5:8])\n",
    "        camera_id = int(pose_line[8])\n",
    "        name = pose_line[9]\n",
    "\n",
    "        poses.append({\n",
    "            'name': name,\n",
    "            'image_id': image_id,\n",
    "            'qw': qw, 'qx': qx, 'qy': qy, 'qz': qz,\n",
    "            'tx': tx, 'ty': ty, 'tz': tz\n",
    "        })\n",
    "\n",
    "        # 跳過下一行的 2D points 資訊\n",
    "        i += 2\n",
    "\n",
    "    return pd.DataFrame(poses)\n",
    "\n",
    "\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "def parse_frame_annotations(file_path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parses a nested JSON file of frame annotations and flattens it into a DataFrame.\n",
    "\n",
    "    This function specifically uses pandas.json_normalize to handle the nested\n",
    "    structure, creating separate columns for nested data like 'image.path' and 'viewpoint.R'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the 'frame_annotations.json' file.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: A DataFrame containing the flattened data,\n",
    "                                or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open and load the file's content first\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Use json_normalize to flatten the data into a clean table\n",
    "        ground_truth_df = pd.json_normalize(data)\n",
    "        return ground_truth_df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: The file was not found at '{file_path}'\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ Error: The file at '{file_path}' is not a valid JSON.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd626bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Filtering for sequence: 110_13051_23361 ---\n",
      "Found 202 matching frames in ground truth.\n",
      "\n",
      "--- Sorting by frame number to ensure correct sequence ---\n",
      "\n",
      "--- Final, Cleaned, and Sorted Data ---\n",
      "              name  frame_number        qw        qx        qy        qz  \\\n",
      "0  frame000001.jpg             1  0.999999 -0.001639  0.000317 -0.000082   \n",
      "1  frame000002.jpg             2  1.000000 -0.000355  0.000677 -0.000270   \n",
      "2  frame000003.jpg             3  0.999999  0.000557  0.000702 -0.000634   \n",
      "3  frame000004.jpg             4  0.999998  0.001311  0.001161 -0.000914   \n",
      "4  frame000005.jpg             5  0.999995  0.002528  0.001562 -0.001090   \n",
      "\n",
      "         tx        ty        tz  \\\n",
      "0  0.055844 -1.761651  0.985386   \n",
      "1  0.041557 -1.742804  0.996667   \n",
      "2  0.030375 -1.726939  1.008236   \n",
      "3  0.027887 -1.714112  1.013429   \n",
      "4  0.032747 -1.702738  1.019127   \n",
      "\n",
      "                                         viewpoint.R  \\\n",
      "0  [[-0.9983327388763428, -0.007844997569918633, ...   \n",
      "1  [[-0.9983288645744324, -0.007622952107340097, ...   \n",
      "2  [[-0.9982747435569763, -0.007153465412557125, ...   \n",
      "3  [[-0.9982591867446899, -0.006701637990772724, ...   \n",
      "4  [[-0.9982641339302063, -0.00664658285677433, -...   \n",
      "\n",
      "                                         viewpoint.T  \n",
      "0  [-0.880431592464447, 5.909038543701172, 10.833...  \n",
      "1  [-0.8357591032981873, 5.860936164855957, 10.90...  \n",
      "2  [-0.806608259677887, 5.818721771240234, 10.906...  \n",
      "3  [-0.8045202493667603, 5.785451412200928, 10.88...  \n",
      "4  [-0.8286618590354919, 5.7538957595825195, 10.8...  \n"
     ]
    }
   ],
   "source": [
    "PREDICTED_PATH = '/media/daniel/storage1/2.research/1.3d-reconstruct/results/CO3D/110_13051_23361/text/images.txt'\n",
    "GT_PATH = '/media/daniel/storage1/2.research/1.3d-reconstruct/dataset/CO3D/apple/frame_annotations.json'\n",
    "TARGET_SEQUENCE = \"110_13051_23361\" # The sequence name from the file path\n",
    "\n",
    "predicted_df = parse_images_txt(PREDICTED_PATH)\n",
    "ground_truth_df = parse_frame_annotations(GT_PATH)\n",
    "\n",
    "if predicted_df is not None and ground_truth_df is not None:\n",
    "    # --- Filter Ground Truth to the specific sequence ---\n",
    "    print(f\"\\n--- Filtering for sequence: {TARGET_SEQUENCE} ---\")\n",
    "    filtered_gt_df = ground_truth_df[ground_truth_df['sequence_name'] == TARGET_SEQUENCE].copy()\n",
    "    print(f\"Found {len(filtered_gt_df)} matching frames in ground truth.\")\n",
    "\n",
    "    # --- Prepare the key for merging ---\n",
    "    filtered_gt_df['filename'] = filtered_gt_df['image.path'].str.split('/').str[-1]\n",
    "\n",
    "    # --- Perform a CLEAN merge ---\n",
    "    merged_df = pd.merge(\n",
    "            predicted_df,\n",
    "            filtered_gt_df,\n",
    "            left_on='name',\n",
    "            right_on='filename'\n",
    "        )\n",
    "\n",
    "    # --- Sort the final result by frame number ---\n",
    "    print(\"\\n--- Sorting by frame number to ensure correct sequence ---\")\n",
    "    merged_df.sort_values(by='frame_number', inplace=True)\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"\\n--- Final, Cleaned, and Sorted Data ---\")\n",
    "    print(merged_df[['name', 'frame_number', 'qw', 'qx', 'qy', 'qz', 'tx', 'ty', 'tz', 'viewpoint.R', 'viewpoint.T']].head())\n",
    "\n",
    "    # merged_df.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "    # import matplotlib.pyplot as plt\n",
    "\n",
    "    # Extract ground truth translation components\n",
    "    # gt_T = pd.DataFrame(merged_df['viewpoint.T'].to_list(), columns=['gt_tx', 'gt_ty', 'gt_tz'])\n",
    "\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.title('Predicted vs. Ground Truth Camera Trajectory (X-axis)')\n",
    "    # plt.xlabel('Frame Number')\n",
    "    # plt.ylabel('X Translation')\n",
    "    # plt.plot(merged_df['frame_number'], merged_df['tx'], label='Predicted TX', marker='.')\n",
    "    # plt.plot(merged_df['frame_number'], gt_T['gt_tx'], label='Ground Truth TX', marker='.')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78ab86",
   "metadata": {},
   "source": [
    "## Convert Quaternion to Rotation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c82e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name                                   pred_viewpoint_R\n",
      "0    frame000001.jpg  [[0.9999997855363876, 0.00016294812650218226, ...\n",
      "1    frame000002.jpg  [[0.9999989362109638, 0.000539926128578973, 0....\n",
      "2    frame000003.jpg  [[0.9999982091438151, 0.0012692536169403813, 0...\n",
      "3    frame000004.jpg  [[0.9999956351318855, 0.001830993221596829, 0....\n",
      "4    frame000005.jpg  [[0.9999927454323816, 0.002187878140049406, 0....\n",
      "..               ...                                                ...\n",
      "197  frame000198.jpg  [[0.9993601278158781, -0.02268173731189705, 0....\n",
      "198  frame000199.jpg  [[0.9993914489637736, -0.02147576701304468, 0....\n",
      "199  frame000200.jpg  [[0.9994587303140047, -0.020892163129824025, 0...\n",
      "200  frame000201.jpg  [[0.9994978211021945, -0.020653738528080848, 0...\n",
      "201  frame000202.jpg  [[0.999522353469453, -0.01900210169045953, 0.0...\n",
      "\n",
      "[202 rows x 2 columns]\n",
      "                name                                   pred_viewpoint_T\n",
      "0    frame000001.jpg  [0.055843573628215286, -1.761651239606333, 0.9...\n",
      "1    frame000002.jpg  [0.0415568167719727, -1.7428044340056856, 0.99...\n",
      "2    frame000003.jpg  [0.030375331859232607, -1.726938613985395, 1.0...\n",
      "3    frame000004.jpg  [0.027887207326433974, -1.7141124385716688, 1....\n",
      "4    frame000005.jpg  [0.032747167476111526, -1.7027381081124044, 1....\n",
      "..               ...                                                ...\n",
      "197  frame000198.jpg  [-0.10314760267744895, -0.9055987942582326, 0....\n",
      "198  frame000199.jpg  [-0.10600001800529268, -0.9046406472900711, 0....\n",
      "199  frame000200.jpg  [-0.11703658083204804, -0.9033512970555522, 0....\n",
      "200  frame000201.jpg  [-0.1158011417872244, -0.9006170014375198, 0.3...\n",
      "201  frame000202.jpg  [-0.11815448411357253, -0.9003876669964694, 0....\n",
      "\n",
      "[202 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "post_processed_df = merged_df[['name', 'frame_number', 'qw', 'qx', 'qy', 'qz', 'tx', 'ty', 'tz','viewpoint.R', 'viewpoint.T']].copy()\n",
    "\n",
    "def quat_to_matrix(row):\n",
    "    # 四元數順序為 [x, y, z, w]\n",
    "    quaternion = [row['qx'], row['qy'], row['qz'], row['qw']]    \n",
    "    # 進行轉換\n",
    "    rotation = R.from_quat(quaternion)\n",
    "    return rotation.as_matrix() # 返回 3x3 numpy array\n",
    "\n",
    "def trans_to_vector(row):\n",
    "    return np.array([row['tx'], row['ty'], row['tz']])\n",
    "\n",
    "post_processed_df['pred_viewpoint_R'] = post_processed_df.apply(quat_to_matrix, axis=1)\n",
    "post_processed_df['pred_viewpoint_T'] = post_processed_df.apply(trans_to_vector, axis=1)\n",
    "\n",
    "print(post_processed_df[['name', 'pred_viewpoint_R']])\n",
    "print(post_processed_df[['name', 'pred_viewpoint_T']])\n",
    "\n",
    "post_processed_df[['name', 'frame_number', 'pred_viewpoint_R', 'pred_viewpoint_T', 'viewpoint.R', 'viewpoint.T']].to_csv('post_processed_df.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0545f",
   "metadata": {},
   "source": [
    "## Compute Predicted Camera Pose RRE, RTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 所有成對 RRE 的統計結果 ---\n",
      "count    20301.000000\n",
      "mean        71.346005\n",
      "std         42.467144\n",
      "min          0.115154\n",
      "25%         32.343159\n",
      "50%         75.267177\n",
      "75%        112.042494\n",
      "max        143.455819\n",
      "dtype: float64\n",
      "\n",
      "RRE@15°: 12.87%\n",
      "\n",
      "--- 所有成對 RTE 的統計結果 ---\n",
      "count    20301.000000\n",
      "mean        13.994741\n",
      "std         10.998033\n",
      "min          0.047213\n",
      "25%          4.458407\n",
      "50%         11.548816\n",
      "75%         20.188088\n",
      "max         99.419709\n",
      "dtype: float64\n",
      "\n",
      "RTE@15°: 59.80%\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# 獲取所有列的索引\n",
    "indices = post_processed_df.index.tolist()\n",
    "\n",
    "# 生成所有可能的索引對 (i, j)\n",
    "all_pairs = list(combinations(indices, 2))\n",
    "\n",
    "rre_errors = [] # 用來存放所有成對的 RRE 結果\n",
    "rte_errors = [] # 用來存放所有成對的 RTE 結果\n",
    "\n",
    "# 遍歷所有成對的組合\n",
    "for i, j in all_pairs:\n",
    "    # --- 獲取旋轉矩陣 (並確保是 numpy array) ---\n",
    "    R_pred_i = np.array(post_processed_df.loc[i, 'pred_viewpoint_R'])\n",
    "    R_pred_j = np.array(post_processed_df.loc[j, 'pred_viewpoint_R'])\n",
    "    R_gt_i = np.array(post_processed_df.loc[i, 'viewpoint.R'])\n",
    "    R_gt_j = np.array(post_processed_df.loc[j, 'viewpoint.R'])\n",
    "    \n",
    "    # --- 獲取平移向量 (並確保是 numpy array) ---\n",
    "    T_pred_i = np.array(post_processed_df.loc[i, 'pred_viewpoint_T'])\n",
    "    T_pred_j = np.array(post_processed_df.loc[j, 'pred_viewpoint_T'])\n",
    "    T_gt_i = np.array(post_processed_df.loc[i, 'viewpoint.T'])\n",
    "    T_gt_j = np.array(post_processed_df.loc[j, 'viewpoint.T'])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # RRE 計算\n",
    "    # -----------------------------------------------------------------\n",
    "    R_relative_pred = np.dot(R_pred_j, R_pred_i.T)\n",
    "    R_relative_gt = np.dot(R_gt_j, R_gt_i.T)\n",
    "    error_matrix = np.dot(R_relative_pred, R_relative_gt.T)\n",
    "    trace = np.trace(error_matrix)\n",
    "    angle_rad = np.arccos(np.clip((trace - 1) / 2, -1.0, 1.0))\n",
    "    angle_deg = np.rad2deg(angle_rad)\n",
    "    rre_errors.append(angle_deg)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # RTE 計算\n",
    "    # -----------------------------------------------------------------\n",
    "    # 1. 計算相機中心點 C = -R^T * T\n",
    "    C_pred_i = -np.dot(R_pred_i.T, T_pred_i)\n",
    "    C_pred_j = -np.dot(R_pred_j.T, T_pred_j)\n",
    "    C_gt_i = -np.dot(R_gt_i.T, T_gt_i)\n",
    "    C_gt_j = -np.dot(R_gt_j.T, T_gt_j)\n",
    "    \n",
    "    # 2. 計算相對平移向量 (兩個相機中心點的連線)\n",
    "    T_relative_pred = C_pred_j - C_pred_i\n",
    "    T_relative_gt = C_gt_j - C_gt_i\n",
    "    \n",
    "    # 3. 正規化向量 (轉換為單位向量) 以計算夾角\n",
    "    # 加上一個極小值 epsilon 防止除以零的錯誤\n",
    "    epsilon = 1e-8\n",
    "    T_relative_pred_norm = T_relative_pred / (np.linalg.norm(T_relative_pred) + epsilon)\n",
    "    T_relative_gt_norm = T_relative_gt / (np.linalg.norm(T_relative_gt) + epsilon)\n",
    "    \n",
    "    # 4. 計算兩個單位向量之間的夾角\n",
    "    dot_product = np.dot(T_relative_pred_norm, T_relative_gt_norm)\n",
    "    angle_rad_t = np.arccos(np.clip(dot_product, -1.0, 1.0))\n",
    "    angle_deg_t = np.rad2deg(angle_rad_t)\n",
    "    rte_errors.append(angle_deg_t)\n",
    "\n",
    "\n",
    "# --- 統計 RRE 結果 ---\n",
    "rre_series = pd.Series(rre_errors)\n",
    "print(\"--- 所有成對 RRE 的統計結果 ---\")\n",
    "print(rre_series.describe())\n",
    "accuracy_at_15_deg_r = (rre_series < 15).mean() * 100\n",
    "print(f\"\\nRRE@15°: {accuracy_at_15_deg_r:.2f}%\")\n",
    "\n",
    "# --- 統計 RTE 結果 ---\n",
    "rte_series = pd.Series(rte_errors)\n",
    "print(\"\\n--- 所有成對 RTE 的統計結果 ---\")\n",
    "print(rte_series.describe())\n",
    "accuracy_at_15_deg_t = (rte_series < 15).mean() * 100\n",
    "print(f\"\\nRTE@15°: {accuracy_at_15_deg_t:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf13775",
   "metadata": {},
   "source": [
    "## Compute Predicted Camera Pose AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48239c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC@30° (mAA): 12.69\n"
     ]
    }
   ],
   "source": [
    "def calculate_auc(rre_series, rte_series, max_threshold=30):\n",
    "    \"\"\"\n",
    "    計算 AUC (mAA) 分數\n",
    "    \n",
    "    參數:\n",
    "    rre_series (pd.Series): 包含所有成對 RRE 誤差的 Series\n",
    "    rte_series (pd.Series): 包含所有成對 RTE 誤差的 Series\n",
    "    max_threshold (int): 積分的最高閾值，論文中通常為 30\n",
    "    \n",
    "    返回:\n",
    "    float: AUC 分數\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracies = []\n",
    "    # 步驟 1: 設定閾值範圍從 1 到 max_threshold\n",
    "    thresholds = range(1, max_threshold + 1)\n",
    "    \n",
    "    # 步驟 2: 計算每個閾值的「綜合準確率」\n",
    "    for t in thresholds:\n",
    "        # a. 計算 RRE 在閾值 t 下的準確率\n",
    "        acc_rre = (rre_series < t).mean()\n",
    "        \n",
    "        # b. 計算 RTE 在閾值 t 下的準確率\n",
    "        acc_rte = (rte_series < t).mean()\n",
    "        \n",
    "        # c. 取兩者中的最小值\n",
    "        acc_at_t = min(acc_rre, acc_rte)\n",
    "        \n",
    "        accuracies.append(acc_at_t)\n",
    "        \n",
    "    # 步驟 3: 計算所有準確率的平均值\n",
    "    auc_score = np.mean(accuracies)\n",
    "    \n",
    "    return auc_score\n",
    "\n",
    "# --- 計算並打印 AUC@30° ---\n",
    "auc_30 = calculate_auc(rre_series, rte_series, max_threshold=30)\n",
    "\n",
    "# 論文中的 AUC 分數通常乘以 100\n",
    "print(f\"\\nAUC@30° (mAA): {auc_30 * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043f572",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vggsfm_tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
